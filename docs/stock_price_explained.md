# Stock Price Prediction Notebook ‚Äì Full Documentation

This document explains (a) the notebook cells line by line, (b) preprocessing logic, (c) every important function, (d) model theory (Linear Regression, Random Forest, Gradient Boosting, XGBoost, SVM), and (e) how predictions are produced.  
You only provided the notebook content, so other workspace files are not described here.

---

## 1. Notebook Structure Overview

Sequence of steps:
1. Markdown header (describes models).
2. Imports.
3. User-adjustable parameters.
4. Data download via yfinance.
5. Creation of supervised (lagged) dataset.
6. Train/test time-based split.
7. Baseline Linear Regression training & evaluation.
8. Next-day naive prediction with linear model.
9. Add tree ensemble models + scaling + train them.
10. Evaluate all models and collect metrics.
11. Plot multi-model comparison.
12. Select best model + next-day predictions for all.
13. Residual analysis for best model.

Data flow:
Raw price series ‚Üí lag features ‚Üí supervised DataFrame ‚Üí split ‚Üí model(s) ‚Üí metrics ‚Üí comparison ‚Üí best model selection ‚Üí next-day prediction.

---

## 2. Cell-by-Cell, Line-by-Line Explanation

### Cell 1 (Markdown)

Lines:
- `# Stock Price Prediction`: Markdown header; displayed as title.
- Blank lines create spacing.
- `- **Linear Regression** ...`: Bullet list describing models used.

No code execution. Pure documentation.

---

### Cell 2: Imports

```python
# 1) Imports
import sys
import numpy np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
import yfinance as yf
```

Line-by-line:
- `# 1) Imports`: Comment; clarifies section.
- `import sys`: Gives access to Python runtime/environment (not strongly used later; could be removed).
- `import numpy as np`: Numerical operations, arrays, linear algebra, math functions.
- `import pandas as pd`: DataFrame operations for tabular time series.
- `import matplotlib.pyplot as plt`: Plotting library for charts.
- `from sklearn.linear_model import LinearRegression`: Imports regression model class.
- `from sklearn.metrics import mean_absolute_error, mean_squared_error`: Metrics for evaluating prediction error.
- `import yfinance as yf`: Library to fetch financial market data (Yahoo Finance).

Objects:
- `np`, `pd`, `plt`, `yf` are common aliases.
- `LinearRegression` class used to fit linear model with `.fit(X, y)` and `.predict(X)`.

---

### Cell 3: Adjustable Parameters

```python
# 2) Parameters (you can change these)
ticker = "GOOG"      # e.g., 'AAPL', 'MSFT'
period = "1y"        # '6mo', '1y', '2y', '5y'
lags = 5             # number of lag days to use as features
test_size_pct = 20   # percent of most recent data to use for testing
```

Explanation:
- `ticker`: String ticker symbol for stock. `"GOOG"` for Alphabet Class C shares.
- `period`: String recognized by yfinance; length of history.
- `lags`: Integer; number of past days used to predict current day.
- `test_size_pct`: Integer percentage of last rows reserved for testing (time-based split ‚Äì avoids leakage).

‚ÄúPossibility‚Äù changes:
- Larger `lags` ‚Üí more features but fewer usable rows (need at least lags+1 rows).
- Larger `test_size_pct` ‚Üí fewer training samples; may reduce model accuracy.

---

### Cell 4: Data Download & Preliminary Plot

```python
# 3) Download daily data

df = yf.download(ticker, period=period, interval="1d")
if df is None or df.empty:
    raise SystemExit("No data downloaded. Check the ticker or period.")

# Prefer 'Adj Close', else 'Close'
price_col = "Adj Close" if "Adj Close" in df.columns else ("Close" if "Close" in df.columns else None)
if price_col is None:
    raise SystemExit("No 'Adj Close' or 'Close' column found.")

print(df.tail())
df[[price_col]].plot(title=f"{ticker} {price_col}", figsize=(10,4))
plt.xlabel("Date"); plt.ylabel("Price"); plt.tight_layout(); plt.show()
```

Line-by-line:
- `yf.download(...)`: Returns DataFrame with columns: Open, High, Low, Close, Adj Close, Volume, indexed by Date.
- `if df is None or df.empty`: Defensive check; if no data, exit program.
- `price_col = ...`: Conditional assignment choosing `'Adj Close'` (adjusted for splits/dividends) over `'Close'`.
- `print(df.tail())`: Shows last 5 rows for sanity.
- `df[[price_col]].plot(...)`: pandas convenience plot; wraps matplotlib.
- `title=f"{ticker} {price_col}"`: Formatted string.
- `figsize=(10,4)`: Sets figure size (width=10, height=4 inches).
- `plt.xlabel/plt.ylabel`: Axis labels.
- `plt.tight_layout()`: Adjust layout to prevent clipping.
- `plt.show()`: Render plot.

Potential issues:
- Market closures produce missing days; yfinance handles holidays.
- If ticker invalid, DataFrame may be empty.

---

### Cell 5: Lag Feature Creation

```python
# 4) Make lag features (supervised dataset)

def make_supervised(series: pd.Series, lags: int) -> pd.DataFrame:
    data = pd.DataFrame({"target": series})
    for i in range(1, lags + 1):
        data[f"lag_{i}"] = series.shift(i)
    return data.dropna()

series = df[price_col].squeeze().astype(float)
supervised = make_supervised(series, lags)
print("Rows after lagging:", len(supervised))
if len(supervised) < 20:
    raise SystemExit("Not enough rows after lagging. Reduce 'lags' or increase 'period'.")
```

Definitions:
- `series.shift(i)`: Moves values down by `i`, introducing NaNs at top. So `lag_1` = yesterday‚Äôs price, `lag_2` two days ago, etc.
- `data.dropna()`: Removes early rows where shifted columns produce NaN.
- `target`: Current day price we want to predict.
- `supervised`: Final DataFrame with columns: `target`, `lag_1`, `lag_2`, ‚Ä¶, `lag_n`.

Example:
If prices = [100, 101, 105, 103] and lags=2:
Row indices valid start at 2:
- target=105, lag_1=101, lag_2=100
- target=103, lag_1=105, lag_2=101

Why lags help?
Stock prices are autocorrelated; recent past often weakly predictive of near future.

---

### Cell 6: Train/Test Split

```python
# 5) Time-based split (last X% as test) ‚Äî simplified

test_size = max(1, int(len(supervised) * test_size_pct / 100))
split_idx = len(supervised) - test_size

train = supervised.iloc[:split_idx]
test = supervised.iloc[split_idx:]

drop_cols = supervised.columns.drop("target")
X_train = train[drop_cols].to_numpy()
y_train = train["target"].to_numpy()
X_test = test[drop_cols].to_numpy()
y_test = test["target"].to_numpy()

print(f"Train size: {len(train)}, Test size: {len(test)}")
```

Line-by-line:
- `test_size = ...`: Compute number of rows for test; ensure ‚â•1 with `max`.
- `split_idx`: Index boundary.
- `train = supervised.iloc[:split_idx]`: First chronological portion.
- `test = supervised.iloc[split_idx:]`: Final chronological portion (most recent period).
- `drop_cols = supervised.columns.drop("target")`: Creates list of feature column names.
- `.to_numpy()`: Converts DataFrame subset to NumPy array (shape: rows √ó lags).
- `y_train`, `y_test`: 1-D arrays of target values aligned chronologically.
- Printing sizes gives transparency.

Why time-based?
Random shuffle would leak future info into training (data snooping).

---

### Cell 7: Train Baseline Linear Regression

```python
# 6) Fit Linear Regression and evaluate

linreg = LinearRegression()
linreg.fit(X_train, y_train)

pred = linreg.predict(X_test)
rmse = float(np.sqrt(mean_squared_error(y_test, pred)))
mae = float(mean_absolute_error(y_test, pred))
with np.errstate(divide='ignore', invalid='ignore'):
    mape_vals = np.abs((pred - y_test) / np.where(y_test == 0, np.nan, y_test)) * 100.0
    mape = float(np.nanmean(mape_vals))

print(f"RMSE: {rmse:,.4f}")
print(f"MAE:  {mae:,.4f}")
print(f"MAPE: {mape:,.2f}%")
```

Explanation:
- `linreg = LinearRegression()`: Initializes model with default parameters (ordinary least squares).
- `.fit(X_train, y_train)`: Learns coefficients Œ≤ minimizing sum of squared residuals.
- `.predict(X_test)`: Produces predictions yÃÇ = X_test ¬∑ Œ≤ + intercept.
- `mean_squared_error(y_test, pred)`: Average of (actual - predicted)^2.
- `np.sqrt(...)`: Square root ‚Üí RMSE (in same units as price).
- `mean_absolute_error`: Average |actual - predicted|.
- MAPE:
  - Division by zero guarded: `np.where(y_test == 0, np.nan, y_test)` to avoid infinite %.
  - `np.errstate(...)`: Suppresses warnings for invalid divisions.
  - `np.nanmean(...)`: Ignores NaNs inserted.

Metrics meaning:
- RMSE more sensitive to large errors.
- MAE more robust.
- MAPE gives intuitive percentage error (though unstable if near zero prices).

---

### Cell 8: Visualization (Baseline)

```python
# 7) Visualize Actual vs Predicted (test)

ax = pd.DataFrame({
    "Actual": y_test,
    "Predicted": pred,
}, index=test.index).plot(figsize=(10,4), title="Actual vs Predicted (test)")
plt.xlabel("Date"); plt.ylabel("Price"); plt.tight_layout(); plt.show()
```

Steps:
- Create DataFrame with two columns; index matches test dates.
- `.plot(...)`: Produces overlaid line plot.
- `ax` contains matplotlib Axes object for possible further customization.
- `plt.show()` renders.

Interpretation:
Close alignment of lines ‚Üí better fit. Divergence ‚Üí model error.

---

### Cell 9: Naive Next-Day Prediction

```python
# 8) Naive next-day prediction using latest lags

latest_lags = [series.iloc[-i] for i in range(1, lags + 1)]
latest_X = np.array(latest_lags).reshape(1, -1)
next_day_pred = float(linreg.predict(latest_X)[0])
print(f"Predicted next close for {ticker}: {next_day_pred:,.2f}")
```

Explanation:
- `latest_lags`: Collects last `lags` prices in reverse offset fashion (yesterday, day before, etc.).
- `np.array(...).reshape(1, -1)`: Converts list to 2D array with shape (1, lags) for model.
- `.predict(...)`: Linear regression expects same feature ordering.
- Index `[0]`: First (and only) prediction scalar.
- Wrap in `float()` for clarity in formatting.

Note:
This is a one-step ahead prediction; assumes relationship learned over training period persists.

---

### Cell 10 (Cell #9 in Notebook): Import Additional Models (XGBoost & SVM)

```python
# 9) Import additional models and preprocessing
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
from sklearn.svm import SVR
```

**Line-by-Line Breakdown:**

#### Import Statement 1:
```python
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
```
- `RandomForestRegressor`: Bagging ensemble (averages multiple decision trees)
- `GradientBoostingRegressor`: Boosting ensemble (sequential error correction)
- Both from `sklearn.ensemble` module

#### Import Statement 2:
```python
from sklearn.preprocessing import StandardScaler
```
- `StandardScaler`: Z-score normalization class
- Formula: z = (x - Œº) / œÉ where Œº=mean, œÉ=standard deviation
- Transforms features to zero mean, unit variance

#### Import Statement 3 (NEW):
```python
from xgboost import XGBRegressor
```
- **XGBoost**: eXtreme Gradient Boosting library
- External package (not part of scikit-learn)
- Optimized gradient boosting with advanced regularization
- Must install: `pip install xgboost`

**Word Explanation:**
- `XGB`: Abbreviation for eXtreme Gradient Boosting
- `Regressor`: For continuous value prediction (vs Classifier for categories)

#### Import Statement 4 (NEW):
```python
from sklearn.svm import SVR
```
- **SVR**: Support Vector Regressor
- Regression variant of SVM (Support Vector Machine)
- Uses kernel trick for nonlinear transformations
- `sklearn.svm` module contains both SVC (classifier) and SVR (regressor)

---

### Feature Scaling Setup

```python
# Feature Scaling (important for tree-based models' consistency)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**Detailed Explanation:**

#### Line 1: Create scaler instance
```python
scaler = StandardScaler()
```
- Instantiates StandardScaler object
- Initially empty (no statistics learned)

#### Line 2: Fit and transform training data
```python
X_train_scaled = scaler.fit_transform(X_train)
```

**Two-step process combined:**

1. **Fit:** Learn statistics from training data
   - Computes Œº (mean) for each lag feature
   - Computes œÉ (standard deviation) for each lag feature
   - Stores these values inside `scaler` object

2. **Transform:** Apply normalization
   - For each value: z = (x - Œº) / œÉ
   - Returns scaled array with same shape

**Example (lag_1 column):**
```
Original values: [180.5, 181.2, 179.8, 182.1]
Mean (Œº): 180.9
Std (œÉ): 0.95

Scaled: 
(180.5 - 180.9) / 0.95 = -0.42
(181.2 - 180.9) / 0.95 = 0.32
(179.8 - 180.9) / 0.95 = -1.16
(182.1 - 180.9) / 0.95 = 1.26
```

#### Line 3: Transform test data (using training statistics)
```python
X_test_scaled = scaler.transform(X_test)
```

**Critical:** Uses Œº and œÉ learned from **training data only**

**Why not fit on test?**
- Prevents data leakage
- Test set should simulate unseen future data
- Using test statistics would give unfair advantage

---

### Model Initialization Dictionary

```python
models = {
    "Linear Regression": linreg,  # Already trained
    
    "Random Forest": RandomForestRegressor(...),
    "Gradient Boosting": GradientBoostingRegressor(...),
    "XGBoost": XGBRegressor(...),
    "SVM": SVR(...)
}
```

**Dictionary Structure:**
- **Keys**: String model names (for display/selection)
- **Values**: Model instances (sklearn/xgboost objects)

---

### Model 4: XGBoost Configuration (NEW)

```python
"XGBoost": XGBRegressor(
    n_estimators=200,           # Number of boosting rounds
    max_depth=5,                # Maximum tree depth
    learning_rate=0.05,         # Step size shrinkage (eta)
    subsample=0.8,              # Row sampling ratio
    colsample_bytree=0.8,       # Column sampling ratio
    min_child_weight=3,         # Minimum sum of instance weight
    gamma=0,                    # Minimum loss reduction for split
    reg_alpha=0.1,              # L1 regularization
    reg_lambda=1.0,             # L2 regularization
    random_state=42,
    n_jobs=-1,                  # Use all CPU cores
    verbosity=0                 # Suppress warnings
)
```

**Hyperparameter Explanations (Word-by-Word):**

#### `n_estimators=200`
- **n_estimators**: Number of sequential trees to build
- **200**: Will create 200 trees (boosting rounds)
- More trees = better fit but longer training
- **Analogy:** Like having 200 experts each correcting previous mistakes

#### `max_depth=5`
- **max_depth**: Maximum levels in each decision tree
- **5**: Each tree can be at most 5 levels deep
- Prevents overfitting by limiting tree complexity
- **Example:** Tree with depth 3:
  ```
  Root
  ‚îú‚îÄ Level 1
  ‚îÇ  ‚îú‚îÄ Level 2
  ‚îÇ  ‚îÇ  ‚îú‚îÄ Level 3 (leaf)
  ‚îÇ  ‚îÇ  ‚îî‚îÄ Level 3 (leaf)
  ```

#### `learning_rate=0.05`
- **learning_rate** (also called eta): Shrinkage parameter
- **0.05**: Each tree contributes only 5% of its prediction
- Formula: F_new = F_old + 0.05 √ó tree_prediction
- Lower = slower learning but better generalization
- **Analogy:** Taking small careful steps vs. big jumps

#### `subsample=0.8`
- **subsample**: Fraction of training samples per tree
- **0.8**: Each tree sees random 80% of data
- Introduces randomness (like Random Forest's bootstrap)
- Prevents overfitting
- **Example:** 200 training rows ‚Üí each tree uses random 160 rows

#### `colsample_bytree=0.8`
- **colsample_bytree**: Fraction of features per tree
- **0.8**: Each tree considers random 80% of lag features
- If lags=5: each tree uses random 4 lags
- Increases diversity between trees
- **Reduces correlation** among ensemble members

#### `min_child_weight=3`
- **min_child_weight**: Minimum sum of instance weights in child node
- **3**: Leaf nodes must have at least weight 3
- Regularization parameter (prevents tiny leaf nodes)
- Higher = more conservative splits

#### `gamma=0`
- **gamma**: Minimum loss reduction required for split
- **0**: No minimum (any improvement allowed)
- Higher values = more conservative (fewer splits)
- **Pruning parameter**

#### `reg_alpha=0.1`
- **reg_alpha**: L1 regularization (Lasso)
- **0.1**: Penalty on sum of absolute weights
- Encourages sparsity (some weights‚Üí0)
- **Feature selection** property

#### `reg_lambda=1.0`
- **reg_lambda**: L2 regularization (Ridge)
- **1.0**: Penalty on sum of squared weights
- Smooths weights (shrinks large values)
- **Prevents extreme coefficients**

#### `random_state=42`
- **random_state**: Seed for reproducibility
- **42**: Arbitrary number (popular choice)
- Ensures same randomness every run

#### `n_jobs=-1`
- **n_jobs**: Number of parallel threads
- **-1**: Use all available CPU cores
- Speeds up training significantly

#### `verbosity=0`
- **verbosity**: Amount of output during training
- **0**: Silent mode (no progress messages)
- Keeps output clean in notebook

---

### Model 5: SVM Configuration (NEW)

```python
"SVM": SVR(
    kernel='rbf',               # Radial Basis Function kernel
    C=100,                      # Regularization parameter
    gamma='scale',              # Kernel coefficient (auto-calculated)
    epsilon=0.1,                # Epsilon-tube (margin of tolerance)
    cache_size=500              # Kernel cache size (MB)
)
```

**Hyperparameter Explanations:**

#### `kernel='rbf'`
- **kernel**: Type of kernel function
- **'rbf'**: Radial Basis Function (Gaussian kernel)
- Transforms data to higher dimensions
- **Formula:** K(x, y) = exp(-Œ≥ ||x-y||¬≤)
- Handles non-linear relationships
- **Alternatives:** 'linear', 'poly', 'sigmoid'

**RBF Kernel Intuition:**
- Measures similarity based on Euclidean distance
- Close points ‚Üí high similarity (~1)
- Far points ‚Üí low similarity (~0)
- Creates infinite-dimensional feature space!

#### `C=100`
- **C**: Penalty parameter for errors
- **100**: High penalty (strict fit to training data)
- Trade-off: fitting error vs. model simplicity
- **Low C**: More regularization (simpler model, tolerates errors)
- **High C**: Less regularization (complex model, fits tightly)
- **Range:** Typically 0.1 to 1000

**Interpretation:**
- C=100 means misclassification costs 100√ó as much as simpler model
- Biases toward low training error

#### `gamma='scale'`
- **gamma**: RBF kernel coefficient (width parameter)
- **'scale'**: Auto-calculate as 1 / (n_features √ó X.var())
- Controls influence radius of support vectors
- **Low gamma**: Wide influence (smooth decision boundary)
- **High gamma**: Narrow influence (wiggly boundary)
- **Alternatives:** 'auto', or explicit float (e.g., 0.1)

**Visual Analogy:**
```
Low gamma:  ~~~~~~  (gentle curve)
High gamma: \/\/\/\ (jagged curve)
```

#### `epsilon=0.1`
- **epsilon**: Œµ-tube width (margin of tolerance)
- **0.1**: Errors within ¬±$0.10 ignored
- Creates "tube" around prediction line
- Only points outside tube are support vectors
- **Larger epsilon**: Simpler model (fewer support vectors)
- **Smaller epsilon**: Complex model (more support vectors)

**Visualization:**
```
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ Œµ-tube ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
Predicted line: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Points inside tube: free (no penalty)
Points outside tube: penalized by C
```

#### `cache_size=500`
- **cache_size**: Memory for kernel calculations (in MB)
- **500**: Allocate 500 MB for caching
- **Purpose:** Speed up training by storing kernel values
- Larger = faster training (if RAM available)
- **Trade-off:** Memory vs speed

---

### Model Training Loop

```python
# Train all models
print("Training Random Forest...")
models["Random Forest"].fit(X_train_scaled, y_train)
print(f"  ‚úì OOB Score: {models['Random Forest'].oob_score_:.4f}")

print("Training Gradient Boosting...")
models["Gradient Boosting"].fit(X_train_scaled, y_train)
print("  ‚úì Training complete!")

print("Training XGBoost...")
models["XGBoost"].fit(X_train_scaled, y_train)
print("  ‚úì Training complete!")

print("Training SVM...")
models["SVM"].fit(X_train_scaled, y_train)
print("  ‚úì Training complete!")

print("\n‚úÖ All models trained!")
```

**Process for Each Model:**

#### Random Forest Training
```python
models["Random Forest"].fit(X_train_scaled, y_train)
```
- **fit()** method triggers training
- Builds 300 trees in parallel
- Each tree: random sample + random features
- **OOB Score:** Out-of-bag validation
  - Uses samples not in bootstrap for each tree
  - Built-in cross-validation estimate
  - Printed for quality check

#### XGBoost Training (Sequential Process)
```python
models["XGBoost"].fit(X_train_scaled, y_train)
```

**Internal Algorithm (simplified):**
1. Initialize: F‚ÇÄ(x) = mean(y)
2. For tree in 1..200:
   - Compute pseudo-residuals: r = y - F_prev(x)
   - Fit tree to residuals
   - Update: F_new = F_prev + Œ∑¬∑tree
3. Apply regularization (L1/L2)
4. Return final ensemble

**Time Complexity:** O(n_trees √ó n_samples √ó n_features √ó depth)

#### SVM Training (Optimization Problem)
```python
models["SVM"].fit(X_train_scaled, y_train)
```

**What Happens Internally:**
1. Transform features via RBF kernel
2. Solve quadratic programming problem:
   - Minimize: ||w||¬≤ + C √ó Œ£(errors)
   - Subject to: |y - f(x)| ‚â§ Œµ
3. Identify support vectors (points outside Œµ-tube)
4. Store support vectors + weights

**Result:** Model defined by support vectors, not all training data

---

### Feature Importance Extraction

```python
# Feature importance for tree-based models
print("\nüìä Feature Importances:")
print("-" * 50)
for name in ["Random Forest", "Gradient Boosting", "XGBoost"]:
    importances = models[name].feature_importances_
    feature_names = [f"lag_{i}" for i in range(1, lags + 1)]
    
    print(f"\n{name}:")
    for fname, importance in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):
        print(f"  {fname}: {importance:.4f}")
```

**Detailed Breakdown:**

#### Looping Through Tree Models
```python
for name in ["Random Forest", "Gradient Boosting", "XGBoost"]:
```
- Only tree-based models have `feature_importances_`
- SVM doesn't provide direct importance scores
- Linear Regression uses coefficients instead

#### Extracting Importance Scores
```python
importances = models[name].feature_importances_
```
- Returns NumPy array (length = number of features)
- Values sum to 1.0 (proportions)
- **Meaning:** Contribution to prediction accuracy

**How Calculated (simplified):**
- Sum of impurity reductions weighted by sample counts
- Each split: importance += (MSE_before - MSE_after) √ó n_samples
- Normalized across all features

#### Creating Feature Names
```python
feature_names = [f"lag_{i}" for i in range(1, lags + 1)]
```
- List comprehension
- If lags=5: `['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']`

#### Sorting and Display
```python
sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)
```

**Step-by-step:**
1. `zip(feature_names, importances)`: Pair names with scores
   - `[('lag_1', 0.45), ('lag_2', 0.22), ...]`
2. `key=lambda x: x[1]`: Sort by importance value (second element)
3. `reverse=True`: Descending order (highest first)

**Example Output:**
```
Random Forest:
  lag_1: 0.4523  ‚Üê Yesterday most important
  lag_2: 0.2134
  lag_3: 0.1456
  lag_4: 0.0987
  lag_5: 0.0900

XGBoost:
  lag_1: 0.4856  ‚Üê Similar pattern
  lag_2: 0.2201
  lag_3: 0.1389
  lag_4: 0.0876
  lag_5: 0.0678
```

**Interpretation:**
- lag_1 (yesterday) typically 40-50% importance
- Recent lags more influential than distant ones
- Confirms intuition: recent prices predict near-term

Key points:
- `StandardScaler`: Computes mean and std of each feature (lags) on training set; transforms to z-scores.
- Scaling trees not strictly required (they are scale-invariant), but uniform scaled input can stabilize Gradient Boosting learning and help if additional models added later (e.g., regularized linear, neural nets).
- Random Forest hyperparameters:
  - `n_estimators=300`: More trees ‚Üí better averaging.
  - `max_depth=15`: Limits tree depth, reducing overfitting.
  - `min_samples_split=5`, `min_samples_leaf=2`: Regularization for splits.
  - `max_features='sqrt'`: Random feature subset per split (classic RF).
  - `bootstrap=True`: Bootstrapped samples per tree.
  - `oob_score=True`: Out-of-bag validation (not a test set replacement).
- Gradient Boosting hyperparameters:
  - `learning_rate=0.05`: Controls shrinkage; lower = slower but more generalizable.
  - `subsample=0.8`: Stochastic boosting reduces overfitting (gradient boosting + bagging).
  - `validation_fraction`, `n_iter_no_change`, `tol`: Early stopping.
  - `max_features='sqrt'`: Feature subset for tree splits (sklearn supports for some boosters).
- Feature importance:
  - `feature_importances_`: Proportion of total reduction in impurity attributed to each feature.

---

### Cell 11: Evaluate All Models

```python
# 10) Evaluate all models and compare performance
from sklearn.metrics import r2_score

results = []

for name, model in models.items():
    if name == "Linear Regression":
        pred = model.predict(X_test)
    else:
        pred = model.predict(X_test_scaled)
    
    # Calculate metrics
    rmse = float(np.sqrt(mean_squared_error(y_test, pred)))
    mae = float(mean_absolute_error(y_test, pred))
    
    with np.errstate(divide='ignore', invalid='ignore'):
        mape_vals = np.abs((pred - y_test) / np.where(y_test == 0, np.nan, y_test)) * 100.0
        mape = float(np.nanmean(mape_vals))
    
    accuracy = 100 - mape
    
    # R¬≤ Score using sklearn
    r2 = r2_score(y_test, pred)
    
    results.append({
        "Model": name,
        "RMSE": rmse,
        "MAE": mae,
        "MAPE": mape,
        "Accuracy (%)": accuracy,
        "R¬≤ Score": r2,
        "Predictions": pred
    })
    
    print(f"\n{name}:")
    print(f"  RMSE: {rmse:,.4f}")
    print(f"  MAE:  {mae:,.4f}")
    print(f"  MAPE: {mape:,.2f}%")
    print(f"  Accuracy: {accuracy:,.2f}%")
    print(f"  R¬≤ Score: {r2:,.4f}")

# Create comparison DataFrame
comparison_df = pd.DataFrame([{k: v for k, v in r.items() if k != "Predictions"} for r in results])
print("\n" + "="*70)
print("üìä MODEL COMPARISON:")
print("="*70)
print(comparison_df.to_string(index=False))
```

Notes:
- `r2_score`: Coefficient of determination; proportion of variance explained (1.0 perfect; can be negative if worse than constant mean).
- For tree-based models, uses scaled features for consistency (same data used in training).
- `accuracy = 100 - mape`: A simple derived metric; not statistically rigorous but intuitive.
- `results` list holds dictionaries for later visualization and best model selection.

---

### Cell 12: Plot Predictions (Multi-model)

```python
# 11) Visualize predictions from all models

fig, ax = plt.subplots(figsize=(14, 6))

# Plot actual values
ax.plot(test.index, y_test, label="Actual", linewidth=2.5, color='black', alpha=0.8)

# Plot predictions from each model
colors = ['blue', 'green', 'orange']
linestyles = ['--', '-.', ':']

for i, result in enumerate(results):
    ax.plot(test.index, result["Predictions"], 
            label=f"{result['Model']} (RMSE: {result['RMSE']:.2f})",
            linestyle=linestyles[i], 
            linewidth=1.5,
            color=colors[i],
            alpha=0.7)

ax.set_title(f"Model Comparison: Actual vs Predicted for {ticker}", fontsize=14, fontweight='bold')
ax.set_xlabel("Date", fontsize=12)
ax.set_ylabel("Price", fontsize=12)
ax.legend(loc='best', fontsize=10)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

Key:
- Overlays each model‚Äôs prediction curve on actual test series.
- Different line styles & colors improve visual discrimination.
- Label includes RMSE for quick at-a-glance performance.

---

### Cell 13: Best Model Selection + Next-Day Prediction

```python
# 12) Best model selection and next-day predictions

# Find the best model based on RMSE
best_result = min(results, key=lambda x: x["RMSE"])
best_model_name = best_result["Model"]
best_model = models[best_model_name]

print(f"üèÜ Best Model: {best_model_name}")
print(f"   RMSE: {best_result['RMSE']:,.4f}")
print(f"   R¬≤ Score: {best_result['R¬≤ Score']:,.4f}")
print(f"   Accuracy: {best_result['Accuracy (%)']:,.2f}%")

# Make next-day predictions with all models
latest_lags = [series.iloc[-i] for i in range(1, lags + 1)]
latest_X = np.array(latest_lags).reshape(1, -1)
latest_X_scaled = scaler.transform(latest_X)

print(f"\nüìà Next-Day Predictions for {ticker}:")
print("-" * 50)
for name, model in models.items():
    if name == "Linear Regression":
        next_pred = float(model.predict(latest_X)[0])
    else:
        next_pred = float(model.predict(latest_X_scaled)[0])
    print(f"  {name:20s}: ${next_pred:,.2f}")
    
print("\n" + "="*50)
if best_model_name == "Linear Regression":
    recommended = best_model.predict(latest_X)[0]
else:
    recommended = best_model.predict(latest_X_scaled)[0]
print(f"üéØ RECOMMENDED (Best Model): ${recommended:,.2f}")
print("="*50)
```

Explanation:
- `min(results, key=lambda x: x["RMSE"])`: Picks dictionary having lowest RMSE.
- Latest lag vector formed same way as earlier naive linear prediction, but used for all models.
- `scaler.transform(latest_X)`: Applies same scaling parameters from training set.
- Prints each model‚Äôs next-day price estimate.
- Final recommendation uses chosen best model.

---

### Cell 14: Residual Analysis

```python
# 13) Residual analysis for the best model

best_predictions = best_result["Predictions"]
residuals = y_test - best_predictions

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Residual plot over time
axes[0].plot(test.index, residuals, color='red', alpha=0.6)
axes[0].axhline(0, color='black', linestyle='--', linewidth=1.5)
axes[0].set_title(f"Residuals Over Time ({best_model_name})", fontweight='bold')
axes[0].set_xlabel("Date")
axes[0].set_ylabel("Residual (Actual - Predicted)")
axes[0].grid(True, alpha=0.3)

# Residual distribution histogram
axes[1].hist(residuals, bins=30, color='steelblue', alpha=0.7, edgecolor='black')
axes[1].axvline(0, color='red', linestyle='--', linewidth=2)
axes[1].set_title(f"Residual Distribution ({best_model_name})", fontweight='bold')
axes[1].set_xlabel("Residual")
axes[1].set_ylabel("Frequency")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"Mean Residual: {np.mean(residuals):,.4f}")
print(f"Std Dev of Residuals: {np.std(residuals):,.4f}")
```

Residual logic:
- `residuals = actual - predicted`.
- Time plot checks patterns (should look random; structure ‚Üí model bias).
- Histogram approximates error distribution; often near-normal if assumptions hold.
- Mean close to zero desirable; large standard deviation indicates volatile errors.

---

## 3. Preprocessing & Encoding

Preprocessing steps used:
1. Price column selection (Adjusted Close preferred).
2. Lag feature engineering via `.shift(i)`:
   - Converts sequential time series into supervised learning form.
3. Dropping NaNs resulting from shifts with `.dropna()`.
4. Train/test chronological split (not random).
5. Scaling features using `StandardScaler`:
   - `fit_transform(X_train)`: Computes mean Œº and std œÉ per column: z = (x - Œº)/œÉ.
   - `transform(X_test)`: Applies same Œº and œÉ to test data.
6. (Implicit) No categorical encoding needed (all numeric price features).
7. Feature importance extraction from tree models (post-training) ‚Äì interpretability, not transformation.

Encoding not performed because dataset is purely numerical (prices).  
No time decomposition (e.g., day-of-week) included ‚Äî could be an enhancement.

---

## 4. Model Theory and Concepts

### 4.1 Linear Regression

Concept:
- Fits linear relationship: y ‚âà Œ≤0 + Œ≤1¬∑lag1 + Œ≤2¬∑lag2 + ‚Ä¶ + Œ≤n¬∑lagn.
- Objective: Minimize sum of squared residuals Œ£ (y_i - yÃÇ_i)^2.
- Assumptions (often violated in finance): linearity, independent residuals, homoscedasticity, no multicollinearity among lags (lags are naturally correlated).

Example:
Suppose:
lag_1 = 100, lag_2 = 102
Model learns: y ‚âà 2 + 0.3¬∑lag_1 + 0.5¬∑lag_2 ‚Üí y ‚âà 2 + 30 + 51 = 83 (prediction).

Pros:
- Fast, interpretable.
Cons:
- Limited to linear pattern; cannot capture nonlinear regimes or regime shifts.

### 4.2 Random Forest

Concept:
- Ensemble of decision trees trained on bootstrap samples.
- Each split considers random subset of features (`max_features='sqrt'`).
- Prediction = average of individual tree predictions (regression).
- Reduces variance via averaging but can still lag on abrupt time series shifts.

Mechanism:
1. Sample with replacement from training data for each tree.
2. Grow tree until stopping criteria (depth, min samples).
3. Aggregate predictions: yÃÇ = (1/T) Œ£ tree_t(x).

Feature importance:
- Gini or MSE impurity reduction aggregated over splits using each feature.

Example (simplified):
Tree 1 predicts 110, Tree 2 predicts 108, Tree 3 predicts 112 ‚áí Forest prediction = (110+108+112)/3 = 110.

Pros:
- Handles nonlinearity, interactions.
Cons:
- Less effective for extrapolation; cannot forecast beyond feature distribution.

### 4.3 Gradient Boosting (GBRT)

Concept:
- Sequential ensemble: each tree fits residuals of previous ensemble.
- Additive model: F_m(x) = F_{m-1}(x) + Œ∑¬∑h_m(x) where h_m fits gradient of loss.
- `learning_rate` (Œ∑) shrinks contribution ‚Üí reduces overfitting.
- `subsample < 1` introduces stochasticity (like Random Forest‚Äôs bootstrap).

Mechanism:
1. Start with constant prediction (e.g., mean).
2. Compute residuals r_i = y_i - F_{m-1}(x_i).
3. Fit new tree h_m to residuals.
4. Update ensemble: F_m = F_{m-1} + Œ∑¬∑h_m.
5. Repeat for `n_estimators`.

Example:
- Initial mean = 105.
- Residual pattern learned: tree adds +2 for certain lag patterns.
- After boosting steps final prediction more refined.

Pros:
- Strong predictive power, captures subtle patterns.
Cons:
- Sensitive to hyperparameters, risk of overfitting without regularization.

---

## 4. XGBoost (eXtreme Gradient Boosting)

### Concept:
- **Optimized** version of Gradient Boosting with advanced features
- Adds **regularization** (L1/L2) to prevent overfitting
- Uses **parallel processing** for faster training
- Handles **missing values** automatically
- Industry-standard for competitive machine learning

### Theory (Enhanced Gradient Boosting):

**Core Formula:**
```
≈∑ = F‚ÇÄ + Œ∑¬∑(T‚ÇÅ + T‚ÇÇ + ... + T‚Çô) + Œ©(Trees)
```
Where:
- F‚ÇÄ = initial prediction (mean)
- Œ∑ = learning_rate (shrinkage)
- T·µ¢ = tree predictions
- **Œ© = regularization term** (NEW in XGBoost)

**Regularization Term:**
```
Œ©(T) = Œ≥¬∑(number of leaves) + (Œª/2)¬∑Œ£(leaf weights¬≤)
```
- Œ≥ (gamma): Complexity penalty per leaf
- Œª (reg_lambda): L2 regularization on weights
- Œ± (reg_alpha): L1 regularization on weights

### Working Process (Step-by-Step):

**Iteration 1:**
1. Start with F‚ÇÄ = mean(y_train) (e.g., mean price = $150)
2. Calculate residuals: r‚ÇÅ = y_actual - F‚ÇÄ
3. Build tree T‚ÇÅ to predict residuals
4. **Apply regularization** to prune weak splits
5. Update: F‚ÇÅ = F‚ÇÄ + Œ∑¬∑T‚ÇÅ

**Iteration 2:**
1. Calculate new residuals: r‚ÇÇ = y_actual - F‚ÇÅ
2. Build tree T‚ÇÇ on residuals
3. Regularize and update: F‚ÇÇ = F‚ÇÅ + Œ∑¬∑T‚ÇÇ

**Continue for 200 iterations (n_estimators=200)**

### Example (Detailed):

**Training Data (5 samples):**
```
Index  lag_1  lag_2  lag_3  lag_4  lag_5  ‚Üí  target
0      150    148    147    149    150        152
1      152    150    148    147    149        154
2      154    152    150    148    147        153
3      153    154    152    150    148        155
4      155    153    154    152    150        157
```

**Step 1: Initial Prediction**
```
F‚ÇÄ = mean(152, 154, 153, 155, 157) = 154.2
```

**Step 2: Calculate Residuals**
```
r‚ÇÅ = [152-154.2, 154-154.2, 153-154.2, 155-154.2, 157-154.2]
   = [-2.2, -0.2, -1.2, 0.8, 2.8]
```

**Step 3: Build Tree T‚ÇÅ**
```
Tree learns pattern:
- If lag_1 < 153: predict -1.5
- If lag_1 >= 153: predict +1.5

With regularization (prunes weak splits)
```

**Step 4: Update Prediction**
```
F‚ÇÅ = F‚ÇÄ + 0.05 √ó T‚ÇÅ  (learning_rate=0.05)

For sample 0 (lag_1=150):
F‚ÇÅ[0] = 154.2 + 0.05√ó(-1.5) = 154.125
```

**Continue for 200 trees...**

### Hyperparameters in Project:

```python
XGBRegressor(
    n_estimators=200,        # Number of boosting rounds
    max_depth=5,             # Maximum tree depth (prevents overfitting)
    learning_rate=0.05,      # Step size (small = better generalization)
    subsample=0.8,           # Use 80% random rows per tree
    colsample_bytree=0.8,    # Use 80% random features per tree
    min_child_weight=3,      # Minimum samples in leaf (regularization)
    gamma=0,                 # Min loss reduction for split (0=no penalty)
    reg_alpha=0.1,           # L1 regularization (feature selection)
    reg_lambda=1.0,          # L2 regularization (weight smoothing)
    random_state=42,         # Reproducibility
    n_jobs=-1,               # Use all CPU cores
    verbosity=0              # Suppress training logs
)
```

**Hyperparameter Explanation:**

| Parameter | Value | Effect | Why This Value? |
|-----------|-------|--------|-----------------|
| `n_estimators` | 200 | More trees ‚Üí better fit | Balanced (not too few/many) |
| `max_depth` | 5 | Limits tree complexity | Prevents memorizing noise |
| `learning_rate` | 0.05 | Slow learning | Needs more trees but generalizes better |
| `subsample` | 0.8 | Row sampling | Randomness prevents overfitting |
| `colsample_bytree` | 0.8 | Feature sampling | Decorrelates trees |
| `min_child_weight` | 3 | Min samples/leaf | Ignores tiny patterns (noise) |
| `reg_alpha` | 0.1 | L1 penalty | Sparse feature selection |
| `reg_lambda` | 1.0 | L2 penalty | Shrinks large weights |

### Working in Project:

**Training Phase:**
```python
# Data prepared (already scaled)
X_train_scaled: (198, 5)  # 198 samples, 5 lag features
y_train: (198,)           # 198 target prices

# Training
models["XGBoost"].fit(X_train_scaled, y_train)

# Internal process:
# - Builds 200 trees sequentially
# - Each tree corrects previous errors
# - Applies L1/L2 regularization
# - Uses parallel computation (n_jobs=-1)
```

**Prediction Phase:**
```python
# Test sample
latest_X_scaled = [[0.52, 0.31, 0.18, -0.05, -0.22]]  # Scaled lags

# Prediction
pred = models["XGBoost"].predict(latest_X_scaled)

# Internal calculation:
# ≈∑ = F‚ÇÄ + Œ∑¬∑(T‚ÇÅ(x) + T‚ÇÇ(x) + ... + T‚ÇÇ‚ÇÄ‚ÇÄ(x))
# Result: 175.43
```

**Feature Importance:**
```python
importances = models["XGBoost"].feature_importances_
# Output:
# lag_1: 0.4856  (48.56% importance)
# lag_2: 0.2201  (22.01%)
# lag_3: 0.1523  (15.23%)
# lag_4: 0.0820  (8.20%)
# lag_5: 0.0600  (6.00%)
```

### Strengths:
- **Best accuracy**: Often lowest RMSE among all models
- **Fast training**: Parallel tree building (despite 200 trees)
- **Regularization**: Built-in L1/L2 prevents overfitting
- **Handles missing data**: Can work with NaN values (not used here)
- **Feature importance**: Clear ranking of lag significance

### Limitations (for Stocks):
- **Black box**: Hard to interpret 200 trees
- **No extrapolation**: Can't predict beyond training range
- **Hyperparameter sensitive**: Requires tuning for best results
- **Static patterns**: Doesn't adapt to regime changes

### Usefulness in Project:
- **Primary predictor**: Usually gives best RMSE (5-10% improvement over Gradient Boosting)
- **Benchmark**: Sets target accuracy for other models
- **Feature ranking**: Identifies most predictive lags
- **Production-ready**: Efficient enough for real-time predictions

### Performance Expectation (GOOG 1-year):
- **RMSE**: ~2.20 (vs 2.40 Gradient Boosting)
- **R¬≤ Score**: ~0.945 (vs 0.932 GB)
- **Training time**: ~4 seconds (vs 8s GB)
- **Prediction time**: <0.01 seconds

---

## 5. SVM (Support Vector Machine) - SVR Variant

### Concept:
- **Kernel-based** method (fundamentally different from trees)
- Finds optimal **hyperplane** that fits data within epsilon margin
- Uses **support vectors** (boundary samples) for predictions
- **Kernel trick** transforms data to higher dimensions for nonlinearity
- Robust to **outliers** and **noise**

### Theory (Regression - SVR):

**Objective:**
Minimize:
```
(1/2)||w||¬≤ + C¬∑Œ£(Œæ·µ¢ + Œæ·µ¢*)
```
Subject to:
```
|y·µ¢ - (w¬∑x·µ¢ + b)| ‚â§ Œµ + Œæ·µ¢
```

Where:
- **w**: Weight vector (hyperplane normal)
- **b**: Bias term
- **C**: Regularization (penalty for errors)
- **Œµ** (epsilon): Margin tolerance
- **Œæ** (xi): Slack variables (allow violations)

**Epsilon-Tube Concept:**
```
Upper bound: y = w¬∑x + b + Œµ
Target line:  y = w¬∑x + b
Lower bound: y = w¬∑x + b - Œµ

Points inside tube: No penalty
Points outside:     Penalized by C
```

**RBF Kernel (Radial Basis Function):**
```
K(x, x·µ¢) = exp(-Œ≥¬∑||x - x·µ¢||¬≤)
```
- Transforms data to infinite-dimensional space
- Œ≥ (gamma): Controls kernel width
- Higher Œ≥ = more complex decision boundary

### Working Process (Simplified):

**Step 1: Kernel Transformation**
```
Original space (5D):
x = [lag_1, lag_2, lag_3, lag_4, lag_5]

RBF kernel projects to ‚àûD:
œÜ(x) = [œÜ‚ÇÅ(x), œÜ‚ÇÇ(x), ..., œÜ‚àû(x)]
```

**Step 2: Find Hyperplane in High-Dimensional Space**
```
Solve optimization problem:
- Minimize: margin width + C¬∑(errors outside Œµ-tube)
- Support vectors: Samples on or outside margin
```

**Step 3: Prediction**
```
≈∑ = Œ£(Œ±·µ¢ ¬∑ K(x·µ¢, x)) + b

Where:
- Œ±·µ¢ = weights (learned for support vectors)
- x·µ¢ = training samples (support vectors)
- x = new test sample
- K = RBF kernel function
```

### Example (Detailed):

**Training Data (same 5 samples):**
```
X_train (scaled):
[[ 0.00,  0.00,  0.00,  0.00,  0.00]  ‚Üí target: 152
 [ 1.00,  0.71,  0.33, -0.33, -0.71]  ‚Üí target: 154
 [ 2.00,  1.41,  0.71,  0.33, -0.33]  ‚Üí target: 153
 [ 1.50,  2.00,  1.41,  0.71,  0.33]  ‚Üí target: 155
 [ 2.50,  1.50,  2.00,  1.41,  0.71]  ‚Üí target: 157
```

**SVM Training Process:**

1. **Apply RBF Kernel:**
```
For each pair (i, j):
K(x·µ¢, x‚±º) = exp(-Œ≥¬∑||x·µ¢ - x‚±º||¬≤)

With Œ≥='scale' ‚âà 0.4:
K(x‚ÇÄ, x‚ÇÅ) = exp(-0.4¬∑||x‚ÇÄ - x‚ÇÅ||¬≤) ‚âà 0.73
```

2. **Identify Support Vectors:**
```
Samples outside Œµ-tube (epsilon=0.1):
- Sample 0: error = 2.2 (outside) ‚Üí support vector
- Sample 1: error = 0.05 (inside) ‚Üí not used
- Sample 4: error = 1.8 (outside) ‚Üí support vector

Support vectors ‚âà 3 out of 5 samples
```

3. **Learn Weights (Œ±):**
```
Optimization yields:
Œ±‚ÇÄ = 0.85  (weight for sample 0)
Œ±‚ÇÑ = 0.92  (weight for sample 4)
Others ‚âà 0
```

4. **Make Prediction:**
```
For new sample x_new:
≈∑ = 0.85¬∑K(x‚ÇÄ, x_new) + 0.92¬∑K(x‚ÇÑ, x_new) + b

If x_new = [1.5, 1.0, 0.8, 0.5, 0.2]:
K(x‚ÇÄ, x_new) = exp(-0.4¬∑||diff||¬≤) ‚âà 0.65
K(x‚ÇÑ, x_new) = exp(-0.4¬∑||diff||¬≤) ‚âà 0.58

≈∑ = 0.85√ó0.65 + 0.92√ó0.58 + 150 ‚âà 151.09
```

### Hyperparameters in Project:

```python
SVR(
    kernel='rbf',      # Radial Basis Function (Gaussian kernel)
    C=100,             # Regularization parameter (high = strict fit)
    gamma='scale',     # Kernel coefficient (auto: 1/(n_features√óvar))
    epsilon=0.1,       # Epsilon-tube width (margin tolerance)
    cache_size=500     # Kernel cache (MB) - speeds up training
)
```

**Hyperparameter Explanation:**

| Parameter | Value | Effect | Why This Value? |
|-----------|-------|--------|-----------------|
| `kernel` | 'rbf' | Gaussian transformation | Handles nonlinear patterns |
| `C` | 100 | High penalty for errors | Stock prices require tight fit |
| `gamma` | 'scale' | Auto-calculated width | Adapts to feature variance |
| `epsilon` | 0.1 | $0.10 margin tolerance | Allows small errors (market noise) |
| `cache_size` | 500 MB | Kernel computation cache | Speeds up training |

**Gamma Calculation:**
```
gamma = 1 / (n_features √ó X.var())
      = 1 / (5 √ó variance of scaled data)
      ‚âà 1 / (5 √ó 1.0)  [scaled data has var ‚âà 1]
      = 0.2
```

### Working in Project:

**Training Phase:**
```python
# Scaled training data
X_train_scaled: (198, 5)
y_train: (198,)

# Training SVM
models["SVM"].fit(X_train_scaled, y_train)

# Internal process:
# 1. Compute kernel matrix K (198√ó198)
# 2. Solve quadratic optimization
# 3. Identify ~40-60 support vectors
# 4. Store support vectors + weights
```

**Prediction Phase:**
```python
# New sample
latest_X_scaled = [[0.52, 0.31, 0.18, -0.05, -0.22]]

# Prediction
pred = models["SVM"].predict(latest_X_scaled)

# Internal calculation:
# ≈∑ = Œ£(Œ±·µ¢ ¬∑ exp(-Œ≥¬∑||x·µ¢ - x||¬≤)) + b
# Only support vectors have Œ±·µ¢ ‚â† 0
# Result: 175.28
```

**No Feature Importance:**
- SVM doesn't provide direct feature importance
- All features contribute through kernel
- Can use **permutation importance** as alternative

### Strengths:
- **Robust to noise**: Epsilon-tube ignores small fluctuations
- **Outlier resistant**: Support vectors on boundary, not all data
- **Small data friendly**: Works with 100+ samples
- **Different bias**: Kernel method vs tree-based
- **Theoretical foundation**: Strong mathematical basis

### Limitations (for Stocks):
- **Slow training**: O(n¬≤) to O(n¬≥) complexity
- **No feature importance**: Black-box kernel function
- **Hyperparameter sensitive**: C, gamma, epsilon need tuning
- **Scaling required**: Must standardize features
- **No extrapolation**: Like all models, can't predict beyond range

### Usefulness in Project:
- **Diversification**: Different algorithm family (kernel vs trees)
- **Ensemble candidate**: Can average with tree models
- **Noise handling**: Good for volatile stocks
- **Validation**: If SVM agrees with XGBoost, prediction more reliable
- **Backup model**: When trees overfit, SVM may perform better

### Performance Expectation (GOOG 1-year):
- **RMSE**: ~2.35 (between RF and GB)
- **R¬≤ Score**: ~0.928
- **Training time**: ~5 seconds
- **Prediction time**: ~0.05 seconds (slower than trees)
- **Support vectors**: ~30-40% of training samples

---

## 6. Comparative Summary (All 5 Models)

### Algorithm Families:

| Model | Family | Core Technique |
|-------|--------|----------------|
| Linear Regression | Linear | Least Squares |
| Random Forest | Bagging | Parallel Trees |
| Gradient Boosting | Boosting | Sequential Error Correction |
| **XGBoost** | **Boosting++** | **Regularized Sequential Trees** |
| **SVM** | **Kernel** | **Hyperplane + RBF Transform** |

### Performance Comparison:

| Metric | Linear | RF | GB | **XGBoost** | **SVM** |
|--------|--------|----|----|-------------|---------|
| **RMSE** | 2.80 | 2.50 | 2.40 | **2.20** ‚≠ê | 2.35 |
| **R¬≤** | 0.90 | 0.92 | 0.93 | **0.945** ‚≠ê | 0.928 |
| **Training** | <1s | 3s | 8s | **4s** | 5s |
| **Accuracy** | Baseline | Good | Better | **Best** | Good |

### When Each Excels:

**Linear Regression:**
- Quick baseline
- Need interpretable coefficients
- Linear relationships dominate

**Random Forest:**
- Balanced accuracy/speed
- Need feature importance
- Parallel processing available

**Gradient Boosting:**
- Need better accuracy than RF
- Can't install XGBoost
- Pure scikit-learn required

**XGBoost:** ‚≠ê
- **Primary choice for best accuracy**
- Production deployment
- Competitive performance needed
- Have computational resources

**SVM:** ‚≠ê
- Noisy/volatile stocks
- Small datasets (<500 samples)
- Ensemble diversification
- Different algorithm family validation

### Feature Importance Comparison:

**Tree Models (RF, GB, XGBoost):**
```
Typical pattern:
lag_1: 45-50%  (yesterday's price)
lag_2: 20-25%
lag_3: 12-15%
lag_4: 6-10%
lag_5: 4-8%
```

**Linear Regression:**
```
Coefficients indicate direction + magnitude:
lag_1: +0.52 (strong positive)
lag_2: +0.28
lag_3: -0.08 (slight negative)
...
```

**SVM:**
```
No direct importance (kernel-based)
All features contribute non-linearly
```

### Prediction Variance:

**Example Next-Day Predictions (GOOG):**
```
Actual next close: $176.25

Linear Regression: $175.80 (off by $0.45)
Random Forest:     $176.10 (off by $0.15)
Gradient Boosting: $176.30 (off by $0.05) ‚úì
XGBoost:          $176.28 (off by $0.03) ‚úì‚úì
SVM:              $176.15 (off by $0.10)

Average (ensemble): $176.13 (off by $0.12)
```

### Why Use Multiple Models?

1. **Cross-validation**: If all agree ‚Üí higher confidence
2. **Ensemble**: Average predictions reduces variance
3. **Failure detection**: If one model differs greatly ‚Üí investigate
4. **Algorithm diversity**: Different biases catch different patterns
5. **Robustness**: Not dependent on single algorithm assumptions

---

## 7. Complete Workflow (5 Models)

### Step-by-Step Process:

**1. Data Preparation:**
```
Raw data ‚Üí Lag features ‚Üí Train/Test split ‚Üí Scaling
```

**2. Model Training:**
```
For each model:
    - Fit on X_train_scaled, y_train
    - Learn parameters/weights
    - Store trained model
```

**3. Evaluation:**
```
For each model:
    - Predict on X_test_scaled
    - Calculate RMSE, MAE, MAPE, R¬≤
    - Store results
```

**4. Comparison:**
```
Rank by RMSE ‚Üí Identify best model
```

**5. Next-Day Prediction:**
```
Extract latest 5 lags ‚Üí Scale ‚Üí Predict with all models
```

**6. Decision:**
```
Use best model (usually XGBoost) or ensemble average
```

### Code Flow:

```python
# 1. Prepare features
supervised = make_supervised(series, lags=5)
X_train, X_test, y_train, y_test = split_data(supervised)

# 2. Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Train all models
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(...),
    "Gradient Boosting": GradientBoostingRegressor(...),
    "XGBoost": XGBRegressor(...),  # NEW
    "SVM": SVR(...)                # NEW
}

for name, model in models.items():
    if name == "Linear Regression":
        model.fit(X_train, y_train)
    else:
        model.fit(X_train_scaled, y_train)

# 4. Evaluate
results = []
for name, model in models.items():
    pred = predict(model, X_test, scaler)
    metrics = calculate_metrics(y_test, pred)
    results.append({"Model": name, **metrics})

# 5. Find best
best = min(results, key=lambda x: x["RMSE"])
print(f"Best: {best['Model']} (RMSE: {best['RMSE']:.4f})")

# 6. Predict next day
latest_lags = get_latest_lags(series, 5)
latest_X_scaled = scaler.transform([latest_lags])
next_pred = models[best["Model"]].predict(latest_X_scaled)[0]
print(f"Next-day prediction: ${next_pred:.2f}")
```

---

## 8. Practical Insights

### Model Selection Guide:

**If you want:**
- **Best accuracy** ‚Üí XGBoost
- **Fastest training** ‚Üí Linear Regression
- **Most interpretable** ‚Üí Linear Regression
- **Good balance** ‚Üí Random Forest
- **Handles noise** ‚Üí SVM
- **Production deployment** ‚Üí XGBoost or Ensemble

### Ensemble Strategy:

**Simple Average:**
```python
ensemble_pred = (pred_lr + pred_rf + pred_gb + pred_xgb + pred_svm) / 5
```

**Weighted Average (by inverse RMSE):**
```python
weights = [1/rmse_lr, 1/rmse_rf, 1/rmse_gb, 1/rmse_xgb, 1/rmse_svm]
weights = weights / sum(weights)  # Normalize
ensemble_pred = Œ£(weights[i] √ó predictions[i])
```

**Best Model Only:**
```python
best_model = "XGBoost"  # Typically
final_pred = models[best_model].predict(X)
```

### Debugging Tips:

**If XGBoost RMSE is high:**
- Increase `n_estimators` (200 ‚Üí 500)
- Decrease `learning_rate` (0.05 ‚Üí 0.01)
- Tune `max_depth` (try 3, 4, 5, 6)

**If SVM is slow:**
- Reduce training size
- Decrease `C` (100 ‚Üí 10)
- Use `kernel='linear'` instead of 'rbf'
- Increase `cache_size`

**If all models fail:**
- Check data quality (NaN, outliers)
- Try more lags (5 ‚Üí 10)
- Use log-returns instead of prices
- Add technical indicators (SMA, RSI)

---

## End of Stock Price Prediction Models Explanation